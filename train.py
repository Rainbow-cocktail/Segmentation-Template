import torch
from pandas.plotting import plot_params

torch.set_float32_matmul_precision('high')
from argparse import ArgumentParser
import numpy as np
import os
import yaml
from datetime import datetime
from pathlib import Path
import shutil

from framework import LightningSeg
import lightning.pytorch as pl
from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping
from lightning.pytorch.loggers import TensorBoardLogger, CSVLogger

from utils import plot_multiclass_metrics


def main(options):
    # è¯»å– YAML é…ç½®æ–‡ä»¶
    with open(options.config, encoding="utf-8") as f:
        config = yaml.safe_load(f)

    # ä¿è¯å®éªŒå¯å¤ç°
    SEED = config.get('SEED', 1234)
    torch.manual_seed(SEED)
    np.random.seed(SEED)

    # åˆå§‹åŒ– Lightning æ¨¡å‹
    model = LightningSeg(model_params=config['model_cfgs'],
                         dataset_params=config['dataset_cfgs'],
                         loss_params=config['loss_cfgs'],
                         train_params=config['train_cfgs'],
                         plot_cfgs=config['plot_cfgs'])


    # å®šä¹‰å®éªŒç‰ˆæœ¬åç§°
    version_name = datetime.now().strftime("run_%Y%m%d-%H%M%S")
    model_name = model.model.name

    # ç”Ÿæˆoutputsç›®å½•
    os.makedirs("outputs", exist_ok=True)

    # è¾“å‡ºç›®å½•
    output_dir = Path("outputs") / model_name / version_name
    log_dir = output_dir / "logs"
    ckpt_dir = output_dir / "checkpoints"
    results_dir = output_dir / "results"
    test_dir = output_dir / "test"
    for d in [log_dir, ckpt_dir, results_dir, test_dir]:
        d.mkdir(parents=True, exist_ok=True)

    # ä¿å­˜è·¯å¾„ä¼ å…¥æ¨¡å‹ï¼Œä¾¿äº framework.py ä¸­ä½¿ç”¨
    model.output_dir = output_dir
    model.results_dir = results_dir
    model.test_dir = test_dir

    # å¤åˆ¶é…ç½®æ–‡ä»¶ä»¥ä¿ç•™å®éªŒå…ƒä¿¡æ¯
    shutil.copy(options.config, output_dir / "config.yaml")

    # å®šä¹‰æ¨¡å‹æ£€æŸ¥ç‚¹å›è°ƒï¼ˆä¿ç•™ val_mIoU æŒ‡æ ‡æœ€ä¼˜æ¨¡å‹ï¼‰
    checkpoint_callback = ModelCheckpoint(
        dirpath=ckpt_dir,
        filename=f"{model_name}--{{epoch:02d}}-{{val_mIoU:.4f}}",
        monitor="val_mIoU",
        save_top_k=1,
        mode="max",
    )

    early_stopping = EarlyStopping(
        monitor="val_loss",
        patience=10,
        mode="min"
    )

    # æ·»åŠ  Loggerï¼šTensorBoard + CSVï¼Œç»Ÿä¸€ version å’Œè·¯å¾„
    logger_tb = TensorBoardLogger(save_dir=log_dir.parent, name="logs", version=version_name)
    logger_csv = CSVLogger(save_dir=log_dir.parent, name="logs", version=version_name)

    device = "gpu" if torch.cuda.is_available() else "cpu"

    trainer = pl.Trainer(
        devices=1,
        accelerator=device,
        max_epochs=config['train_cfgs']['epochs'],
        log_every_n_steps=10,
        callbacks=[checkpoint_callback, early_stopping],
        logger=[logger_tb, logger_csv]
    )

    trainer.fit(model)

    print("==Training finished.ğŸ¾ Take a break and have a cup of coffee. â˜•ï¸==")


    if config["plot_cfgs"]["save_last_epoch_result"] and config["plot_cfgs"]["plot_classification_curve"]:
        import gc
        torch.cuda.empty_cache()
        gc.collect()

        npz_path = os.path.join(output_dir, "results", f"classification_data_epoch{config['train_cfgs']['epochs']}.npz")
        data = np.load(npz_path)
        y_true = data["y_true"]
        y_pred = data["y_pred"]
        class_names = config["dataset_cfgs"]["classes"]
        plot_multiclass_metrics(y_true,
                                y_pred,
                                class_names=class_names,
                                exclude_class_0=True,
                                save_dir=os.path.join(output_dir, "results"))


if __name__ == '__main__':
    root_dir = os.path.dirname(os.path.realpath(__file__))
    parser = ArgumentParser()

    # model and training setup
    parser.add_argument('--config', type=str, help='name a yaml running configuration')
    option = parser.parse_args()

    # ---------------------
    # RUN TRAINING
    # ---------------------
    main(option)
